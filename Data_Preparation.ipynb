{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lorenzrossi/MachineLearning-CatsDogs-NN/blob/master/Data_Preparation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Download the Cats and Dogs Dataset\n",
        "\n",
        "The dataset used is the famous **Dogs vs Cats** dataset from Kaggle:\n",
        "- **Kaggle Competition**: https://www.kaggle.com/c/dogs-vs-cats\n",
        "- **Direct Dataset Link**: https://www.kaggle.com/c/dogs-vs-cats/data\n",
        "\n",
        "The dataset contains 25,000 images of cats and dogs (12,500 each).\n",
        "\n",
        "### Option 1: Download using Kaggle API (Recommended)\n",
        "\n",
        "To use this method, you need to:\n",
        "1. Go to https://www.kaggle.com/account and create an API token\n",
        "2. Upload the `kaggle.json` file to your Colab session\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Detect if running in Google Colab\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "\n",
        "# Install Kaggle API\n",
        "if IN_COLAB:\n",
        "    !pip install -q kaggle\n",
        "else:\n",
        "    import subprocess\n",
        "    import sys\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"kaggle\"])\n",
        "\n",
        "# Setup Kaggle API credentials\n",
        "import os\n",
        "if IN_COLAB:\n",
        "    # Upload your kaggle.json file (run this cell and upload the file when prompted)\n",
        "    from google.colab import files\n",
        "    uploaded = files.upload()\n",
        "    \n",
        "    # Move kaggle.json to the correct location\n",
        "    !mkdir -p ~/.kaggle\n",
        "    !mv kaggle.json ~/.kaggle/\n",
        "    !chmod 600 ~/.kaggle/kaggle.json\n",
        "else:\n",
        "    # For local systems, ensure kaggle.json is in ~/.kaggle/ directory\n",
        "    kaggle_dir = os.path.join(os.path.expanduser('~'), '.kaggle')\n",
        "    os.makedirs(kaggle_dir, exist_ok=True)\n",
        "    print(f\"Please ensure your kaggle.json file is located at: {os.path.join(kaggle_dir, 'kaggle.json')}\")\n",
        "\n",
        "# Download the dataset\n",
        "if IN_COLAB:\n",
        "    !kaggle competitions download -c dogs-vs-cats\n",
        "    download_dir = '/content'\n",
        "    base_dir = '/content/drive/MyDrive/CatsDogs'\n",
        "else:\n",
        "    import subprocess\n",
        "    subprocess.run(['kaggle', 'competitions', 'download', '-c', 'dogs-vs-cats'], check=True)\n",
        "    # Use current directory for local systems\n",
        "    download_dir = os.getcwd()\n",
        "    base_dir = os.path.join(os.getcwd(), 'CatsDogs')\n",
        "\n",
        "# Unzip the training data\n",
        "import zipfile\n",
        "import shutil\n",
        "\n",
        "# Unzip dogs-vs-cats.zip\n",
        "zip_path = os.path.join(download_dir, 'dogs-vs-cats.zip')\n",
        "if os.path.exists(zip_path):\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(download_dir)\n",
        "\n",
        "# Unzip train.zip\n",
        "train_zip_path = os.path.join(download_dir, 'train.zip')\n",
        "train_dir = os.path.join(download_dir, 'train')\n",
        "if os.path.exists(train_zip_path):\n",
        "    with zipfile.ZipFile(train_zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(download_dir)\n",
        "\n",
        "# Create the directory structure expected by the code\n",
        "os.makedirs(os.path.join(base_dir, 'Cats'), exist_ok=True)\n",
        "os.makedirs(os.path.join(base_dir, 'Dogs'), exist_ok=True)\n",
        "os.makedirs(os.path.join(base_dir, 'Pickles'), exist_ok=True)\n",
        "\n",
        "# Organize images into Cats and Dogs folders\n",
        "import glob\n",
        "\n",
        "# Move cat images (files starting with 'cat.')\n",
        "cat_files = glob.glob(os.path.join(train_dir, 'cat.*'))\n",
        "for file in cat_files:\n",
        "    shutil.move(file, os.path.join(base_dir, 'Cats'))\n",
        "\n",
        "# Move dog images (files starting with 'dog.')\n",
        "dog_files = glob.glob(os.path.join(train_dir, 'dog.*'))\n",
        "for file in dog_files:\n",
        "    shutil.move(file, os.path.join(base_dir, 'Dogs'))\n",
        "\n",
        "print(\"Dataset downloaded and organized successfully!\")\n",
        "print(f\"Base directory: {base_dir}\")\n",
        "print(f\"Number of cat images: {len(os.listdir(os.path.join(base_dir, 'Cats')))}\")\n",
        "print(f\"Number of dog images: {len(os.listdir(os.path.join(base_dir, 'Dogs')))}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Option 2: Direct Download (Alternative method)\n",
        "\n",
        "If you prefer not to use Kaggle API, you can download the dataset manually:\n",
        "1. Visit https://www.kaggle.com/c/dogs-vs-cats/data\n",
        "2. Download `train.zip` (requires Kaggle account)\n",
        "3. Extract it and organize images:\n",
        "   - **For Google Colab**: Extract to `/content/drive/MyDrive/CatsDogs/` and organize into `Cats/` and `Dogs/` subdirectories\n",
        "   - **For Local Systems**: Extract to a `CatsDogs/` folder in your current directory and organize into `Cats/` and `Dogs/` subdirectories\n",
        "\n",
        "**Note**: The dataset requires a Kaggle account to download. If you already have the dataset organized, you can skip the download cells above.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8cP3Kq5ohHr",
        "outputId": "a918d268-f936-454a-d46f-f78a20d3243a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "24978\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from os import listdir\n",
        "import pandas as pd\n",
        "# Basic packages\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import random\n",
        "import pickle\n",
        "\n",
        "# Image preprocessing\n",
        "import pathlib\n",
        "import PIL\n",
        "import PIL.Image\n",
        "import cv2\n",
        "\n",
        "# Detect if running in Google Colab\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    # Use Google Drive path for Colab\n",
        "    base_dir = '/content/drive/MyDrive/CatsDogs'\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "    # Use current directory for local systems (Windows, Mac, Linux)\n",
        "    base_dir = os.path.join(os.getcwd(), 'CatsDogs')\n",
        "\n",
        "# Create directories if they don't exist\n",
        "os.makedirs(base_dir, exist_ok=True)\n",
        "os.makedirs(os.path.join(base_dir, 'Cats'), exist_ok=True)\n",
        "os.makedirs(os.path.join(base_dir, 'Dogs'), exist_ok=True)\n",
        "os.makedirs(os.path.join(base_dir, 'Pickles'), exist_ok=True)\n",
        "\n",
        "print(f\"Working directory: {base_dir}\")\n",
        "print(f\"Running in Colab: {IN_COLAB}\")\n",
        "\n",
        "# Import of Data\n",
        "\n",
        "# I define some parameters in order to resize images in a uniform way\n",
        "# Note: I set channels = 1 for grayscale images (using IMREAD_GRAYSCALE)\n",
        "# If you want RGB images, change channels to 3 and use cv2.IMREAD_COLOR instead\n",
        "img_width = 100\n",
        "img_height = 100\n",
        "img_size = (img_width, img_height)\n",
        "channels = 1  # 1 for grayscale, 3 for RGB\n",
        "\n",
        "# Pets is the list in which all the images will be stored\n",
        "pets = []\n",
        "\n",
        "# I define the two categories of pets (related to the sub-directories)\n",
        "categories = ['Cats','Dogs']\n",
        "\n",
        "# I create a function in order to load the data, transform them into arrays, assign them to a class and store them in the pets list\n",
        "def create_data():\n",
        "    # the function iterates through the two sub-directories\n",
        "    for category in categories:\n",
        "        path = os.path.join(base_dir, category)\n",
        "        \n",
        "        # Check if directory exists\n",
        "        if not os.path.exists(path):\n",
        "            print(f\"Warning: Directory {path} does not exist. Please download the dataset first.\")\n",
        "            continue\n",
        "\n",
        "        # assign 0 to cat and 1 to dog, according to the index of the categories\n",
        "        pet_class = categories.index(category)\n",
        "\n",
        "        # the function then iterates through each image in both the folders. I used the opencv (cv2 when imported) package to read and load them. \n",
        "        # IMREAD_COLOR keeps the color in the image, whereas IMREAD_GRAYSCALE would turn them into grayscale images.\n",
        "        # The function resizes the images as defined by the previous parameters and finally appends the array of the image, \n",
        "        # together with the class value (creating a sub-list of two values for each image), to the pets list.\n",
        "        # The function skips those images which seem broken.\n",
        "        for img in os.listdir(path):\n",
        "            try:\n",
        "                img_array = cv2.imread(os.path.join(path,img), cv2.IMREAD_GRAYSCALE)\n",
        "                # Check if image was loaded successfully\n",
        "                if img_array is None:\n",
        "                    continue\n",
        "                #img_array = cv2.bitwise_not(img_array)\n",
        "                new_array = cv2.resize(img_array, img_size)\n",
        "                pets.append([new_array, pet_class])\n",
        "            except Exception as e:\n",
        "                # Print error for debugging (optional - can be removed)\n",
        "                # print(f\"Error loading {img}: {e}\")\n",
        "                pass\n",
        "\n",
        "create_data()\n",
        "\n",
        "print(f\"Total number of images loaded: {len(pets)}\")\n",
        "\n",
        "# since the previous function iterates linearly through the two sub-directories, I shuffle the data in order to mix the order of the images\n",
        "random.shuffle(pets)\n",
        "\n",
        "for sample in pets[:9]:\n",
        "    print(sample[1])\n",
        "\n",
        "# split the data arrays and the labels for the classification task\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "for image, label in pets:\n",
        "    X.append(image)\n",
        "    y.append(label)\n",
        "\n",
        "X = np.array(X).reshape(-1, img_width, img_height, channels)\n",
        "\n",
        "# Save the processed data as pickle files\n",
        "pickles_dir = os.path.join(base_dir, 'Pickles')\n",
        "x_pickle_path = os.path.join(pickles_dir, 'X.pickle')\n",
        "y_pickle_path = os.path.join(pickles_dir, 'y.pickle')\n",
        "\n",
        "pickle_out = open(x_pickle_path, 'wb')\n",
        "pickle.dump(X, pickle_out)\n",
        "pickle_out.close()\n",
        "\n",
        "pickle_out = open(y_pickle_path, 'wb')\n",
        "pickle.dump(y, pickle_out)\n",
        "pickle_out.close()\n",
        "\n",
        "# Load the pickled data to verify\n",
        "pickle_in = open(x_pickle_path, 'rb')\n",
        "X = pickle.load(pickle_in)\n",
        "\n",
        "pickle_in = open(y_pickle_path, 'rb')\n",
        "y = pickle.load(pickle_in)\n",
        "\n",
        "print(f\"Data shape: X = {X.shape}, y = {len(y)} labels\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "36XOqjzxHNgB"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPzMc0GrBGagUgDwi4QR6dP",
      "collapsed_sections": [],
      "include_colab_link": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
